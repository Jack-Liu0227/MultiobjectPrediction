# 修复总结

## 问题1：提示词模板预览API请求格式错误

### 错误现象
```
422 (Unprocessable Entity)
body -> template_name: Field required
body -> template_type: Field required
...
```

### 问题原因
前端发送的请求体将模板字段嵌套在`template_data`对象中，但后端Pydantic模型期望这些字段在顶层。

### 修复方案
采用方案B：修改后端模型，将`template_data`的字段展开到顶层。

### 修改文件
1. **backend/api/prompt_templates.py**
   - 修改`PromptPreviewRequest`类，将所有模板字段提升到顶层
   - 修改`preview_template`函数，从请求对象中提取模板字段构建`template_dict`

2. **frontend/components/PromptTemplateEditor.tsx**
   - 修改预览请求体，使用展开运算符`...currentTemplate`将模板字段展开到顶层

### 修改详情
- 后端模型现在接受顶层字段：`template_name`, `template_type`, `task_description`等
- 前端请求体格式：`{ ...currentTemplate, test_sample, reference_samples, ... }`

---

## 问题2：增量预测的sample_index逻辑错误

### 错误现象
1. 第一次预测5个样本，第二次设置sample_size=7，结果预测了7个新样本（总共12个），而不是新增2个样本（总共7个）
2. sample_index是0, 1, 2...的连续序列，而不是test_set.csv的原始索引

### 问题原因
1. 使用`reset_index(drop=True)`丢失了原始索引
2. 增量预测逻辑错误理解了`sample_size`的含义
3. 基于组分+工艺的键进行过滤，而不是基于索引

### 修复方案
1. 移除所有`reset_index`逻辑，使用DataFrame的原始索引
2. 修改增量预测逻辑，`sample_size`表示"总共要预测多少个样本"
3. 基于已预测的样本索引进行过滤

### 修改文件
**backend/services/rag_prediction_service.py**

#### 修改1：移除_prepare_data中的_original_row_id
- 移除：`df.insert(0, '_original_row_id', range(1, len(df) + 1))`
- 保留：DataFrame的原始索引

#### 修改2：修改_run_multi_target_prediction的采样逻辑
- 移除：`test_df = test_df.reset_index(drop=True)`
- 修改：使用`test_df.sample(n=sample_size, random_state=config.random_seed)`保留原始索引
- 添加：`predicted_indices`参数，用于排除已预测的样本
- 修改：计算需要新增的样本数量：`new_samples_needed = sample_size - len(predicted_indices)`

#### 修改3：修改增量预测的逻辑
- 从`process_details.json`中提取已预测的样本索引
- 检查是否达到目标数量，如果是则直接返回
- 在采样时排除已预测的样本

#### 修改4：修改process_details的合并逻辑
- 移除：使用`composition + processing`作为键
- 修改：使用`sample_index`作为键
- 保持：按`sample_index`升序排序

#### 修改5：移除_save_results中的排序逻辑
- 移除：`if '_original_row_id' in merged_df.columns: merged_df = merged_df.sort_values('_original_row_id')`
- 修改：保持合并后的自然顺序

### 修改详情

#### 增量预测流程（修复后）
1. **第一次预测**（sample_size=5）
   - 划分训练/测试集（test_df保留原始索引）
   - 从test_df中随机选择5个样本（例如索引：[3, 7, 12, 18, 25]）
   - 保存predictions.csv和process_details.json
   - process_details.json中的sample_index为[3, 7, 12, 18, 25]

2. **第二次预测**（sample_size=7，continue_from_task_id=第一次的任务ID）
   - 加载第一次的process_details.json，提取已预测的索引：[3, 7, 12, 18, 25]
   - 计算需要新增的样本数：7 - 5 = 2
   - 从test_df中排除已预测的索引，随机选择2个新样本（例如索引：[1, 9]）
   - 合并predictions.csv和process_details.json
   - 最终process_details.json中的sample_index为[1, 3, 7, 9, 12, 18, 25]（按索引排序）

#### 关键改进
1. **保留原始索引**：sample_index现在是test_set.csv的原始DataFrame索引
2. **正确的增量逻辑**：sample_size表示总数，而不是本次新增数
3. **基于索引而不是内容**：避免了相同组分+工艺的样本被覆盖的问题

---

## 验证建议

### 问题1验证
1. 启动后端服务
2. 在前端打开提示词模板编辑器
3. 点击"预览"按钮
4. 检查是否成功显示渲染后的提示词

### 问题2验证
1. 第一次预测：设置sample_size=5，记录预测的样本索引
2. 第二次预测：设置sample_size=7，使用continue_from_task_id
3. 检查：
   - process_details.json中的sample_index是否为test_set.csv的原始索引
   - 是否只新增了2个样本（总共7个）
   - predictions.csv中的样本是否与test_set.csv中对应索引的样本一致

