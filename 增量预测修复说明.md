# 增量预测 sample_index 修复说明

## 修复概述

本次修复解决了增量预测中 `sample_index` 生成逻辑、采样策略、溯源功能和前端显示的问题，确保：

1. **`sample_index` 是测试集内部的相对索引**（从 0 开始的连续序列），而不是原始 CSV 的绝对索引
2. **采样策略从随机采样改为顺序采样**
3. **增量预测时从已预测的最大索引之后继续顺序选择**
4. **保存 test_set.csv** 到结果目录，便于通过 `sample_index` 定位样本
5. **process_details.json 包含 ID 字段**，便于前端溯源查找
6. **前端正确显示 ID 列**（原始数据的 ID）和溯源信息
7. **前端溯源模态框优先使用 ID 查找**，提高用户体验

## 修改文件

### 后端：`backend/services/rag_prediction_service.py`

#### 1. `_prepare_data` 方法（第371-374行）

**修改：重置测试集索引为从 0 开始的连续序列**

```python
# 重置测试集索引为从 0 开始的连续序列
# 这样 sample_index 就表示"测试集中的第几个样本"，而不是"原始 CSV 的第几行"
test_df = test_df.reset_index(drop=True)
logger.info(f"测试集样本数: {len(test_df)}, 索引范围: 0 - {len(test_df)-1}")
```

**关键改进：**

- 在 `train_test_split` 后立即重置测试集索引
- 确保 `sample_index` 从 0 开始，表示测试集内部的相对位置

#### 2. `run_prediction` 方法（第118-123行）

**修改：保存 test_set.csv 到结果目录**

```python
# 保存测试集到结果目录，便于后续通过 sample_index 定位样本
test_set_file = task_results_dir / "test_set.csv"
test_df.to_csv(test_set_file, index=False)
logger.info(f"Task {task_id}: 测试集已保存到 {test_set_file}")
```

**关键改进：**

- 每次预测任务都保存对应的测试集
- 可以通过 `test_df.iloc[sample_index]` 直接定位样本

#### 3. `_predict_single_sample` 方法（第437-452行）

**修改：为 process_details 添加 ID 字段**

```python
# 返回结果
result_dict = {
    'sample_index': int(test_idx),
    'composition': test_composition_str,
    'processing': test_row[config.processing_column],
    'predictions': result['predictions'],
    'prompt': result.get('prompt', ''),
    'llm_response': result.get('llm_response', ''),
    'similar_samples': similar_samples
}

# 添加 ID 字段（如果存在）
if 'ID' in test_row.index:
    result_dict['ID'] = int(test_row['ID']) if pd.notna(test_row['ID']) else None

return result_dict
```

**关键改进：**

- 从测试集样本中提取 `ID` 字段并添加到 process_details
- 前端可以使用 `ID` 进行溯源查找，提高用户体验

#### 4. `_run_multi_target_prediction` 方法（第475-521行）

**修改前（随机采样）：**

```python
available_test_df = test_df[~test_df.index.isin(predicted_indices)]
actual_sample_size = min(new_samples_needed, len(available_test_df))
if actual_sample_size < len(available_test_df):
    sampled_test_df = available_test_df.sample(n=actual_sample_size, random_state=config.random_seed)
    sampled_test_df = sampled_test_df.sort_index()
else:
    sampled_test_df = available_test_df.sort_index()
```

**修改后（顺序采样）：**

```python
# 按索引排序，保证采样顺序稳定且与测试集索引一致
sorted_indices = sorted(test_df.index.tolist())

if predicted_indices:
    # 找到已预测的最大索引，从下一个索引开始顺序选择
    max_predicted_index = max(predicted_indices)
    candidate_indices = [idx for idx in sorted_indices if idx > max_predicted_index]
else:
    # 首次预测：从第一个索引开始
    candidate_indices = sorted_indices

# 按顺序选取前 actual_sample_size 个样本
selected_indices = candidate_indices[:actual_sample_size]
sampled_test_df = test_df.loc[selected_indices]
```

**关键改进：**

- 移除 `DataFrame.sample()` 随机采样
- 使用 `test_df.loc[selected_indices]` 保留原始索引
- 增量预测时从 `max_predicted_index + 1` 开始顺序选择

#### 5. `_save_results` 方法（第672-761行）

**修改前：**

```python
final_df = test_df.copy().reset_index(drop=True)
```

**修改后：**

```python
# 保留测试集的原始索引，并显式写入 sample_index 列
final_df = test_df.copy()
if "sample_index" not in final_df.columns:
    final_df["sample_index"] = final_df.index.astype(int)

# 重置行索引，仅作为 DataFrame 内部索引使用
final_df = final_df.reset_index(drop=True)

# 将 sample_index 列移动到首列
cols = final_df.columns.tolist()
if "sample_index" in cols:
    cols = ["sample_index"] + [c for c in cols if c != "sample_index"]
    final_df = final_df[cols]
```

**关键改进：**

- 添加显式的 `sample_index` 列到 `predictions.csv`
- `sample_index` 来自 DataFrame 的 `.index` 属性，而不是计数器

#### 6. 增量预测合并逻辑（第693-761行）

**修改前（按组分+工艺去重）：**

```python
# 构建去重键
key_cols = []
if composition_columns:
    key_cols.extend(composition_columns)
if processing_column:
    key_cols.append(processing_column)

if key_cols and all(col in merged_df.columns for col in key_cols):
    merged_df = merged_df.drop_duplicates(subset=key_cols, keep='last')
```

**修改后（按 sample_index 合并）：**

```python
# 使用 sample_index 作为键进行合并
merged_map = {}
for _, row in existing_predictions.iterrows():
    idx = row.get("sample_index")
    if pd.notna(idx):
        merged_map[int(idx)] = row.to_dict()

for _, row in final_df.iterrows():
    idx = row.get("sample_index")
    if pd.notna(idx):
        merged_map[int(idx)] = row.to_dict()

# 按 sample_index 升序排序后转为 DataFrame
sorted_indices = sorted(merged_map.keys())
merged_df = pd.DataFrame([merged_map[idx] for idx in sorted_indices])
```

**关键改进：**

- 使用 `sample_index` 作为唯一键进行合并
- 避免相同组分+工艺的样本被覆盖
- 按 `sample_index` 升序排序，保持顺序一致

### 前端修改

#### `frontend/pages/results/[id].tsx`

**修改1：ID 列显示（第256行）**

```typescript
// 修改前
<td>{row._original_row_id || '-'}</td>

// 修改后
<td>{row.ID !== undefined ? row.ID : (row._original_row_id || '-')}</td>
```

**修改2：溯源模态框传递 sample_index（第252、286行）**

```typescript
// 修改前
setSelectedPoint({ ...row, index: idx });

// 修改后
setSelectedPoint({ ...row, index: row.sample_index !== undefined ? row.sample_index : idx });
```

**关键改进：**

- 前端正确显示原始数据的 `ID` 列
- 溯源功能使用 `sample_index` 而不是表格行索引

#### `frontend/components/PredictionTraceModal.tsx`

**修改：优先使用 ID 查找溯源数据（第59-77行）**

```typescript
// 查找对应样本的详细信息
// 优先使用 ID 查找，如果失败则使用 sample_index 查找
const sampleId = sampleData?.ID;
let sampleTrace = null;

if (sampleId !== undefined && sampleId !== null) {
  // 优先使用 ID 查找
  sampleTrace = processDetails.find((detail: any) => detail.ID === sampleId);
}

if (!sampleTrace) {
  // 回退到使用 sample_index 查找
  sampleTrace = processDetails.find((detail: any) => detail.sample_index === sampleIndex);
}

if (!sampleTrace) {
  const identifier = sampleId !== undefined ? `ID=${sampleId}` : `sample_index=${sampleIndex}`;
  throw new Error(`未找到样本 ${identifier} 的溯源数据`);
}
```

**关键改进：**

- 优先使用用户可见的 `ID` 进行查找
- 提供更友好的错误提示

#### `frontend/components/charts/PredictionScatterChart.tsx`

**修改：散点图使用 sample_index（第39行）**

```typescript
// 修改前
index,

// 修改后
index: pred.sample_index !== undefined ? pred.sample_index : index,
```

**关键改进：**

- 散点图点击事件传递正确的 `sample_index`

#### `frontend/components/PromptTemplateEditor.tsx`

**修改：改进预览错误处理（第283-304行）**

```typescript
const result = await response.json();

console.log('预览响应数据:', result);

// 检查响应数据是否有效
if (!result || typeof result.rendered_prompt === 'undefined') {
  throw new Error('预览响应数据无效：rendered_prompt 为 undefined');
}

// 显示渲染后的完整提示词
const preview = `
=== 渲染后的完整提示词 ===
（使用示例数据：高温合金组分 + 热处理工艺）

${result.rendered_prompt || '（渲染失败）'}

=== 模板变量 ===
${JSON.stringify(result.template_variables || {}, null, 2)}
`.trim();
```

**关键改进：**

- 添加响应数据有效性检查
- 提供更详细的错误信息
- 防止显示 "undefined"

## 验证步骤

### 1. 首次预测（sample_size=6）

运行预测后检查：

```bash
python verify_incremental_fix.py storage/results/<task_id>
```

期望输出：

- `process_details.json` 中的 `sample_index`: [0, 1, 2, 3, 4, 5]
- `predictions.csv` 中的 `sample_index`: [0, 1, 2, 3, 4, 5]
- 溯源文件：`sample_0_*.txt`, `sample_1_*.txt`, ..., `sample_5_*.txt`

### 2. 增量预测（sample_size=7，使用 continue_from_task_id）

运行预测后检查：

```bash
python verify_incremental_fix.py storage/results/<new_task_id>
```

期望输出：

- `process_details.json` 中的 `sample_index`: [0, 1, 2, 3, 4, 5, 6]
- `predictions.csv` 中的 `sample_index`: [0, 1, 2, 3, 4, 5, 6]
- 新增溯源文件：`sample_6_*.txt`
- 日志显示：只新增 1 个样本（索引 6）

### 3. 对比测试集

```bash
python verify_incremental_fix.py storage/results/<task_id> storage/datasets/<dataset_id>/test_set.csv
```

验证 `predictions.csv` 中的样本是否与 `test_set.csv` 中对应索引的样本一致。

## 注意事项

1. **索引来源**：`sample_index` 始终从 DataFrame 的 `.index` 属性获取，对应 `test_set.csv` 的行号
2. **顺序采样**：首次预测从索引 0 开始，增量预测从 `max_predicted_index + 1` 开始
3. **合并策略**：使用 `sample_index` 作为唯一键，新值覆盖旧值（但实际上不应该有重复）
4. **向后兼容**：如果历史结果缺少 `sample_index` 列，会降级为直接追加模式

## 测试结果

所有单元测试已通过：

- ✓ 首次预测：正确选择索引 [0, 1, 2, 3, 4, 5]
- ✓ 增量预测（新增1个）：正确选择索引 [6]
- ✓ 增量预测（新增4个）：正确选择索引 [6, 7, 8, 9]
- ✓ 已达到目标：正确识别无需新增
- ✓ sample_index 保留：正确保留原始 DataFrame 索引

## 相关文件

- `backend/services/rag_prediction_service.py`：主要修改文件
- `verify_incremental_fix.py`：验证脚本
- `增量预测修复说明.md`：本文档

## 修复完成

所有代码修改已完成并通过测试，可以直接使用。
