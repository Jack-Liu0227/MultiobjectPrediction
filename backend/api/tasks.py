"""
ä»»åŠ¡ç®¡ç† API
"""

from fastapi import APIRouter, HTTPException, Query, Body, BackgroundTasks
from typing import Optional
from pydantic import BaseModel
import logging
from pathlib import Path

from models.schemas import TaskListResponse, TaskDetailResponse, TaskInfo, PredictionConfig
from services.task_manager import TaskManager
from services.rag_prediction_service import RAGPredictionService
from database.dataset_db import DatasetDatabase
from config import UPLOAD_DIR, BASE_DIR, RESULTS_DIR

logger = logging.getLogger(__name__)
router = APIRouter()

task_manager = TaskManager()
prediction_service = RAGPredictionService(task_manager)
dataset_db = DatasetDatabase()


# è¯·æ±‚æ¨¡å‹å®šä¹‰
class RerunTaskRequest(BaseModel):
    """é‡æ–°è¿è¡Œä»»åŠ¡è¯·æ±‚"""
    config: Optional[dict] = None  # å¯é€‰çš„é…ç½®è¦†ç›–
    note: Optional[str] = None  # å¯é€‰çš„ä»»åŠ¡å¤‡æ³¨


@router.get("/list", response_model=TaskListResponse)
async def list_tasks(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    status: Optional[str] = Query(None, description="çŠ¶æ€ç­›é€‰"),
    sort_by: str = Query("created_at", description="æ’åºå­—æ®µ"),
    sort_order: str = Query("desc", description="æ’åºé¡ºåº")
):
    """
    è·å–ä»»åŠ¡åˆ—è¡¨
    
    å‚æ•°:
    - page: é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
    - page_size: æ¯é¡µæ•°é‡ï¼ˆ1-100ï¼‰
    - status: çŠ¶æ€ç­›é€‰ï¼ˆpending/running/completed/failedï¼‰
    - sort_by: æ’åºå­—æ®µï¼ˆcreated_at/completed_at/statusï¼‰
    - sort_order: æ’åºé¡ºåºï¼ˆasc/descï¼‰
    
    è¿”å›:
    {
        "tasks": [...],
        "total": 100,
        "page": 1,
        "page_size": 20
    }
    """
    try:
        result = task_manager.list_tasks(
            page=page,
            page_size=page_size,
            status_filter=status,
            sort_by=sort_by,
            sort_order=sort_order
        )
        
        return TaskListResponse(
            tasks=[TaskInfo(**task) for task in result['tasks']],
            total=result['total'],
            page=page,
            page_size=page_size
        )
    
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/{task_id}", response_model=TaskDetailResponse)
async def get_task_detail(task_id: str):
    """
    è·å–ä»»åŠ¡è¯¦æƒ…
    
    å‚æ•°:
    - task_id: ä»»åŠ¡ID
    
    è¿”å›:
    {
        "task": {...},
        "config": {...},
        "logs": [...]
    }
    """
    try:
        task_info = task_manager.get_task(task_id)
        
        if not task_info:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
        
        # è·å–ä»»åŠ¡é…ç½®
        config = task_manager.get_task_config(task_id)
        
        # è·å–ä»»åŠ¡æ—¥å¿—ï¼ˆæœ€è¿‘100æ¡ï¼‰
        logs = task_manager.get_task_logs(task_id, limit=100)
        
        return TaskDetailResponse(
            task=TaskInfo(**task_info),
            config=config,
            logs=logs
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {str(e)}")


@router.delete("/{task_id}")
async def delete_task(task_id: str):
    """
    åˆ é™¤ä»»åŠ¡
    
    å‚æ•°:
    - task_id: ä»»åŠ¡ID
    
    è¿”å›:
    {
        "message": "ä»»åŠ¡å·²åˆ é™¤",
        "task_id": "..."
    }
    """
    try:
        success = task_manager.delete_task(task_id)
        
        if not success:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
        
        return {
            "message": "ä»»åŠ¡å·²åˆ é™¤",
            "task_id": task_id
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/{task_id}/rerun")
async def rerun_task(
    task_id: str,
    background_tasks: BackgroundTasks,
    request: Optional[RerunTaskRequest] = None
):
    """
    é‡æ–°è¿è¡Œä»»åŠ¡ï¼ˆåˆ›å»ºæ–°ä»»åŠ¡å¹¶å¯åŠ¨é¢„æµ‹ï¼‰

    å‚æ•°:
    - task_id: åŸä»»åŠ¡ID
    - request: å¯é€‰çš„é…ç½®å’Œå¤‡æ³¨è¦†ç›–
      - config: é…ç½®è¦†ç›–ï¼ˆå¯é€‰ï¼‰
      - note: ä»»åŠ¡å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰

    è¿”å›:
    {
        "message": "ä»»åŠ¡å·²é‡æ–°æäº¤",
        "new_task_id": "...",
        "original_task_id": "..."
    }
    """
    try:
        import json

        # è·å–åŸä»»åŠ¡ä¿¡æ¯
        original_task = task_manager.get_task(task_id)

        if not original_task:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        # è·å–åŸä»»åŠ¡é…ç½®
        config_dict = task_manager.get_task_config(task_id)

        if not config_dict:
            raise HTTPException(status_code=400, detail="æ— æ³•è·å–ä»»åŠ¡é…ç½®")

        # å¦‚æœè¯·æ±‚ä¸­åŒ…å«é…ç½®è¦†ç›–ï¼Œåˆå¹¶é…ç½®
        if request and request.config:
            logger.info(f"åº”ç”¨é…ç½®è¦†ç›–: {request.config}")
            config_dict.update(request.config)

        # è·å–åŸä»»åŠ¡çš„æ–‡ä»¶ä¿¡æ¯
        # ä¼˜å…ˆä»æ•°æ®åº“ä¸­çš„ request_data è·å–
        request_data = original_task.get("request_data", {})

        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ request_dataï¼Œå°è¯•ä» task_config.json æ–‡ä»¶è¯»å–ï¼ˆå…¼å®¹æ—§ä»»åŠ¡ï¼‰
        if not request_data:
            task_config_file = RESULTS_DIR / task_id / "task_config.json"
            if task_config_file.exists():
                try:
                    with open(task_config_file, 'r', encoding='utf-8') as f:
                        task_config = json.load(f)
                        request_data = task_config.get('request_data', {})
                        logger.info(f"ä» task_config.json è¯»å– request_data: {task_config_file}")
                except Exception as e:
                    logger.warning(f"æ— æ³•ä» task_config.json è¯»å– request_data: {e}")

        if not request_data:
            raise HTTPException(status_code=404, detail=f"æ— æ³•è·å–ä»»åŠ¡ {task_id} çš„æ–‡ä»¶ä¿¡æ¯")

        file_id = request_data.get("file_id")
        dataset_id = request_data.get("dataset_id")
        filename = request_data.get("filename", "")

        # ç¡®å®šæ–‡ä»¶è·¯å¾„
        actual_file_path = None

        # æ–¹æ³•1: ä¼˜å…ˆä½¿ç”¨ dataset_id
        if dataset_id:
            dataset = dataset_db.get_dataset(dataset_id)
            if dataset:
                actual_file_path = Path(dataset["file_path"])
                filename = dataset["original_filename"]  # ä½¿ç”¨åŸå§‹æ–‡ä»¶åè€Œä¸æ˜¯å­˜å‚¨æ–‡ä»¶å
                if actual_file_path.exists():
                    logger.info(f"ä» dataset_id è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")

        # æ–¹æ³•2: å¦‚æœæ²¡æœ‰ dataset_idï¼Œå°è¯•ä½¿ç”¨ file_id
        if (not actual_file_path or not actual_file_path.exists()) and file_id:
            # æ£€æŸ¥æ˜¯å¦ä¸º dataset_id
            dataset = dataset_db.get_dataset(file_id)
            if dataset:
                actual_file_path = Path(dataset["file_path"])
                filename = dataset["original_filename"]  # ä½¿ç”¨åŸå§‹æ–‡ä»¶åè€Œä¸æ˜¯å­˜å‚¨æ–‡ä»¶å
                if actual_file_path.exists():
                    logger.info(f"ä» file_id (ä½œä¸º dataset_id) è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")
            else:
                # å°è¯•ä½œä¸ºä¸Šä¼ æ–‡ä»¶è·¯å¾„
                if filename:
                    actual_file_path = UPLOAD_DIR / file_id / filename
                    if actual_file_path.exists():
                        logger.info(f"ä»ä¸Šä¼ ç›®å½•è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")

        # æ–¹æ³•3: ä» file_path å­—æ®µè·å–ï¼ˆå¯èƒ½æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ï¼‰
        if not actual_file_path or not actual_file_path.exists():
            file_path_str = request_data.get("file_path")
            if file_path_str:
                # å°è¯•ä½œä¸ºç»å¯¹è·¯å¾„
                actual_file_path = Path(file_path_str)
                if not actual_file_path.exists():
                    # å°è¯•ä½œä¸ºç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
                    actual_file_path = BASE_DIR / file_path_str
                    if actual_file_path.exists():
                        logger.info(f"ä» file_path (ç›¸å¯¹è·¯å¾„) è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")
                else:
                    logger.info(f"ä» file_path (ç»å¯¹è·¯å¾„) è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")

        if not actual_file_path or not actual_file_path.exists():
            error_msg = f"æ‰¾ä¸åˆ°åŸä»»åŠ¡çš„æ•°æ®æ–‡ä»¶ã€‚dataset_id={dataset_id}, file_id={file_id}, file_path={request_data.get('file_path')}"
            logger.error(error_msg)
            raise HTTPException(status_code=404, detail=error_msg)

        # åˆ›å»º PredictionConfig å¯¹è±¡
        config = PredictionConfig(**config_dict)

        # åˆ›å»ºæ–°ä»»åŠ¡æ•°æ®
        task_data = {
            "file_path": str(actual_file_path),
            "filename": filename,
            "config": config_dict,
            "total_rows": request_data.get("total_rows"),
            "valid_rows": request_data.get("valid_rows")
        }

        # ä¿å­˜ dataset_id æˆ– file_id
        if dataset_id:
            task_data["dataset_id"] = dataset_id
            task_data["file_id"] = dataset_id
        elif file_id:
            task_data["file_id"] = file_id

        # å¦‚æœè¯·æ±‚ä¸­åŒ…å«å¤‡æ³¨ï¼Œæ·»åŠ åˆ°ä»»åŠ¡æ•°æ®
        if request and request.note:
            task_data["note"] = request.note
            logger.info(f"æ·»åŠ ä»»åŠ¡å¤‡æ³¨: {request.note}")

        # åˆ›å»ºæ–°ä»»åŠ¡
        new_task_id = task_manager.create_task(task_data)
        logger.info(f"Created rerun task: {new_task_id} from original task: {task_id}")

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåœ¨åå°å¯åŠ¨é¢„æµ‹ä»»åŠ¡
        background_tasks.add_task(
            prediction_service.run_prediction,
            task_id=new_task_id,
            file_path=str(actual_file_path),
            config=config
        )

        logger.info(f"Started background prediction for rerun task: {new_task_id}")

        return {
            "message": "ä»»åŠ¡å·²é‡æ–°æäº¤",
            "new_task_id": new_task_id,
            "original_task_id": task_id
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é‡æ–°è¿è¡Œä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é‡æ–°è¿è¡Œä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/{task_id}/incremental-predict")
async def incremental_predict_task(task_id: str, background_tasks: BackgroundTasks):
    """
    å¢é‡é¢„æµ‹ä»»åŠ¡ï¼ˆç»§ç»­é¢„æµ‹æœªå®Œæˆçš„æ ·æœ¬ï¼‰

    å‚æ•°:
    - task_id: åŸä»»åŠ¡ID

    è¿”å›:
    {
        "message": "å¢é‡é¢„æµ‹ä»»åŠ¡å·²å¯åŠ¨",
        "task_id": "...",
        "original_task_id": "..."
    }
    """
    try:
        from models.schemas import PredictionConfig, TaskStatus
        from config import RESULTS_DIR
        import json

        # è·å–åŸä»»åŠ¡ä¿¡æ¯
        original_task = task_manager.get_task(task_id)

        if not original_task:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        # è·å–åŸä»»åŠ¡é…ç½®
        config_dict = task_manager.get_task_config(task_id)

        if not config_dict:
            raise HTTPException(status_code=400, detail="æ— æ³•è·å–ä»»åŠ¡é…ç½®")

        # æ·»åŠ å¢é‡é¢„æµ‹æ ‡å¿—
        config_dict['continue_from_task_id'] = task_id

        # åˆ›å»ºé…ç½®å¯¹è±¡
        config = PredictionConfig(**config_dict)

        # è·å–æ–‡ä»¶è·¯å¾„
        actual_file_path = None
        request_data = original_task.get("request_data", {})
        dataset_id = request_data.get("dataset_id")
        file_id = request_data.get("file_id")

        # æ–¹æ³•1: ä» task_config.json è·å–ï¼ˆé€‚ç”¨äºæ—§ä»»åŠ¡ï¼‰
        task_config_file = RESULTS_DIR / task_id / "task_config.json"
        if task_config_file.exists():
            try:
                with open(task_config_file, 'r', encoding='utf-8') as f:
                    task_config = json.load(f)
                    file_path_str = task_config.get('request_data', {}).get('file_path')
                    if file_path_str:
                        actual_file_path = Path(file_path_str)
                        if actual_file_path.exists():
                            logger.info(f"ä» task_config.json è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")
            except Exception as e:
                logger.warning(f"æ— æ³•ä» task_config.json è¯»å–æ–‡ä»¶è·¯å¾„: {e}")

        # æ–¹æ³•2: ä» dataset_id è·å–
        if not actual_file_path or not actual_file_path.exists():
            if dataset_id:
                dataset = dataset_db.get_dataset(dataset_id)
                if dataset:
                    actual_file_path = Path(dataset['file_path'])
                    if actual_file_path.exists():
                        logger.info(f"ä»æ•°æ®é›†æ•°æ®åº“è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")

        # æ–¹æ³•3: ä» file_id è·å–
        if not actual_file_path or not actual_file_path.exists():
            if file_id:
                # å°è¯•ä»æ•°æ®é›†æ•°æ®åº“è·å–æ–‡ä»¶è·¯å¾„
                dataset = dataset_db.get_dataset(file_id)
                if dataset:
                    actual_file_path = Path(dataset['file_path'])
                    if actual_file_path.exists():
                        logger.info(f"ä»æ•°æ®é›†æ•°æ®åº“è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")
                else:
                    # å°è¯•ä»ä¸Šä¼ ç›®å½•è·å–æ–‡ä»¶
                    file_path = UPLOAD_DIR / file_id
                    if file_path.exists():
                        # æŸ¥æ‰¾å®é™…çš„CSVæ–‡ä»¶
                        csv_files = list(file_path.glob("*.csv"))
                        if csv_files:
                            actual_file_path = csv_files[0]
                            logger.info(f"ä»ä¸Šä¼ ç›®å½•è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")

        # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–æ–‡ä»¶è·¯å¾„
        if not actual_file_path or not actual_file_path.exists():
            raise HTTPException(status_code=404, detail=f"æ— æ³•æ‰¾åˆ°ä»»åŠ¡ {task_id} çš„æ•°æ®æ–‡ä»¶")

        # é‡ç½®ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        task_manager.update_task_status(
            task_id=task_id,
            status=TaskStatus.RUNNING,
            progress=0.0,
            message="å¼€å§‹å¢é‡é¢„æµ‹..."
        )

        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ BackgroundTasks å¯åŠ¨å¢é‡é¢„æµ‹ï¼ˆä¸ rerun_task ä¿æŒä¸€è‡´ï¼‰
        background_tasks.add_task(
            prediction_service.run_prediction,
            task_id=task_id,
            file_path=str(actual_file_path),
            config=config
        )

        logger.info(f"Started background incremental prediction for task: {task_id}")

        return {
            "message": "å¢é‡é¢„æµ‹ä»»åŠ¡å·²å¯åŠ¨",
            "task_id": task_id,
            "original_task_id": task_id
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¢é‡é¢„æµ‹ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¢é‡é¢„æµ‹ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/{task_id}/cancel")
async def cancel_task(task_id: str):
    """
    å–æ¶ˆä»»åŠ¡

    å‚æ•°:
    - task_id: ä»»åŠ¡ID

    è¿”å›:
    {
        "message": "ä»»åŠ¡å·²å–æ¶ˆ",
        "task_id": "..."
    }
    """
    try:
        task_info = task_manager.get_task(task_id)

        if not task_info:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        # åªèƒ½å–æ¶ˆ pending æˆ– running çŠ¶æ€çš„ä»»åŠ¡
        if task_info.get('status') not in ['pending', 'running']:
            raise HTTPException(
                status_code=400,
                detail=f"æ— æ³•å–æ¶ˆçŠ¶æ€ä¸º {task_info.get('status')} çš„ä»»åŠ¡"
            )

        success = task_manager.cancel_task(task_id)

        if not success:
            raise HTTPException(status_code=500, detail="å–æ¶ˆä»»åŠ¡å¤±è´¥")

        return {
            "message": "ä»»åŠ¡å·²å–æ¶ˆ",
            "task_id": task_id
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/batch-cancel")
async def batch_cancel_tasks(task_ids: list[str]):
    """
    æ‰¹é‡å–æ¶ˆä»»åŠ¡

    å‚æ•°:
    - task_ids: ä»»åŠ¡IDåˆ—è¡¨

    è¿”å›:
    {
        "message": "æ‰¹é‡å–æ¶ˆå®Œæˆ",
        "total": æ€»ä»»åŠ¡æ•°,
        "success": æˆåŠŸæ•°é‡,
        "failed": å¤±è´¥æ•°é‡,
        "results": [
            {"task_id": "...", "success": true/false, "message": "..."}
        ]
    }
    """
    try:
        results = []
        success_count = 0
        failed_count = 0

        for task_id in task_ids:
            try:
                task_info = task_manager.get_task(task_id)

                if not task_info:
                    results.append({
                        "task_id": task_id,
                        "success": False,
                        "message": "ä»»åŠ¡ä¸å­˜åœ¨"
                    })
                    failed_count += 1
                    continue

                # åªæœ‰è¿è¡Œä¸­æˆ–ç­‰å¾…ä¸­çš„ä»»åŠ¡å¯ä»¥å–æ¶ˆ
                if task_info.get("status") not in ["running", "pending"]:
                    results.append({
                        "task_id": task_id,
                        "success": False,
                        "message": f"ä»»åŠ¡çŠ¶æ€ä¸º {task_info.get('status')}ï¼Œæ— æ³•å–æ¶ˆ"
                    })
                    failed_count += 1
                    continue

                success = task_manager.cancel_task(task_id)

                if success:
                    results.append({
                        "task_id": task_id,
                        "success": True,
                        "message": "ä»»åŠ¡å·²å–æ¶ˆ"
                    })
                    success_count += 1
                else:
                    results.append({
                        "task_id": task_id,
                        "success": False,
                        "message": "å–æ¶ˆä»»åŠ¡å¤±è´¥"
                    })
                    failed_count += 1

            except Exception as e:
                logger.error(f"å–æ¶ˆä»»åŠ¡ {task_id} å¤±è´¥: {e}", exc_info=True)
                results.append({
                    "task_id": task_id,
                    "success": False,
                    "message": str(e)
                })
                failed_count += 1

        return {
            "message": "æ‰¹é‡å–æ¶ˆå®Œæˆ",
            "total": len(task_ids),
            "success": success_count,
            "failed": failed_count,
            "results": results
        }

    except Exception as e:
        logger.error(f"æ‰¹é‡å–æ¶ˆä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")


class UpdateNoteRequest(BaseModel):
    """æ›´æ–°ä»»åŠ¡å¤‡æ³¨è¯·æ±‚"""
    note: str


@router.patch("/{task_id}/note")
async def update_task_note(task_id: str, request: UpdateNoteRequest):
    """
    æ›´æ–°ä»»åŠ¡å¤‡æ³¨

    å‚æ•°:
    - task_id: ä»»åŠ¡ID
    - note: æ–°çš„å¤‡æ³¨å†…å®¹

    è¿”å›:
    {
        "message": "å¤‡æ³¨å·²æ›´æ–°",
        "task_id": "...",
        "note": "..."
    }
    """
    try:
        # è·å–ä»»åŠ¡ä¿¡æ¯
        task_info = task_manager.get_task(task_id)

        if not task_info:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        # æ›´æ–°å¤‡æ³¨
        task_manager.update_task(task_id, {"note": request.note})

        return {
            "message": "å¤‡æ³¨å·²æ›´æ–°",
            "task_id": task_id,
            "note": request.note
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°ä»»åŠ¡å¤‡æ³¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ›´æ–°ä»»åŠ¡å¤‡æ³¨å¤±è´¥: {str(e)}")
