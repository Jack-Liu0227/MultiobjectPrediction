"""
ä»»åŠ¡ç®¡ç† API
"""

from fastapi import APIRouter, HTTPException, Query, Body, BackgroundTasks
from typing import Optional
from pydantic import BaseModel
import logging
from pathlib import Path

from models.schemas import TaskListResponse, TaskDetailResponse, TaskInfo, PredictionConfig
from services.task_manager import TaskManager
from services.rag_prediction_service import RAGPredictionService
from database.dataset_db import DatasetDatabase
from database.task_db import TaskDatabase
from services.iterative_prediction_service import IterativePredictionService
from services.simple_rag_engine import SimpleRAGEngine
from config import UPLOAD_DIR, BASE_DIR, RESULTS_DIR

logger = logging.getLogger(__name__)
router = APIRouter()

task_manager = TaskManager()
prediction_service = RAGPredictionService(task_manager)
dataset_db = DatasetDatabase()


# è¯·æ±‚æ¨¡å‹å®šä¹‰
class RerunTaskRequest(BaseModel):
    """é‡æ–°è¿è¡Œä»»åŠ¡è¯·æ±‚"""
    config: Optional[dict] = None  # å¯é€‰çš„é…ç½®è¦†ç›–
    note: Optional[str] = None  # å¯é€‰çš„ä»»åŠ¡å¤‡æ³¨


class IncrementalPredictRequest(BaseModel):
    """å¢é‡é¢„æµ‹è¯·æ±‚"""
    config: Optional[dict] = None  # å¯é€‰çš„é…ç½®è¦†ç›–ï¼ˆä¾‹å¦‚å¢åŠ  max_iterationsï¼‰



@router.get("/list", response_model=TaskListResponse)
async def list_tasks(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    status: Optional[str] = Query(None, description="çŠ¶æ€ç­›é€‰"),
    sort_by: str = Query("created_at", description="æ’åºå­—æ®µ"),
    sort_order: str = Query("desc", description="æ’åºé¡ºåº")
):
    """
    è·å–ä»»åŠ¡åˆ—è¡¨
    
    å‚æ•°:
    - page: é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
    - page_size: æ¯é¡µæ•°é‡ï¼ˆ1-100ï¼‰
    - status: çŠ¶æ€ç­›é€‰ï¼ˆpending/running/completed/failedï¼‰
    - sort_by: æ’åºå­—æ®µï¼ˆcreated_at/completed_at/statusï¼‰
    - sort_order: æ’åºé¡ºåºï¼ˆasc/descï¼‰
    
    è¿”å›:
    {
        "tasks": [...],
        "total": 100,
        "page": 1,
        "page_size": 20
    }
    """
    try:
        result = task_manager.list_tasks(
            page=page,
            page_size=page_size,
            status_filter=status,
            sort_by=sort_by,
            sort_order=sort_order
        )
        
        return TaskListResponse(
            tasks=[TaskInfo(**task) for task in result['tasks']],
            total=result['total'],
            page=page,
            page_size=page_size
        )
    
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/{task_id}", response_model=TaskDetailResponse)
async def get_task_detail(task_id: str):
    """
    è·å–ä»»åŠ¡è¯¦æƒ…
    
    å‚æ•°:
    - task_id: ä»»åŠ¡ID
    
    è¿”å›:
    {
        "task": {...},
        "config": {...},
        "logs": [...]
    }
    """
    try:
        task_info = task_manager.get_task(task_id)
        
        if not task_info:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
        
        # è·å–ä»»åŠ¡é…ç½®
        config = task_manager.get_task_config(task_id)
        
        # è·å–ä»»åŠ¡æ—¥å¿—ï¼ˆæœ€è¿‘100æ¡ï¼‰
        logs = task_manager.get_task_logs(task_id, limit=100)
        
        return TaskDetailResponse(
            task=TaskInfo(**task_info),
            config=config,
            logs=logs
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {str(e)}")


@router.delete("/{task_id}")
async def delete_task(task_id: str):
    """
    åˆ é™¤ä»»åŠ¡
    
    å‚æ•°:
    - task_id: ä»»åŠ¡ID
    
    è¿”å›:
    {
        "message": "ä»»åŠ¡å·²åˆ é™¤",
        "task_id": "..."
    }
    """
    try:
        success = task_manager.delete_task(task_id)
        
        if not success:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
        
        return {
            "message": "ä»»åŠ¡å·²åˆ é™¤",
            "task_id": task_id
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/{task_id}/rerun")
async def rerun_task(
    task_id: str,
    background_tasks: BackgroundTasks,
    request: Optional[RerunTaskRequest] = None
):
    """
    é‡æ–°è¿è¡Œä»»åŠ¡ï¼ˆåˆ›å»ºæ–°ä»»åŠ¡å¹¶å¯åŠ¨é¢„æµ‹ï¼‰

    å‚æ•°:
    - task_id: åŸä»»åŠ¡ID
    - request: å¯é€‰çš„é…ç½®å’Œå¤‡æ³¨è¦†ç›–
      - config: é…ç½®è¦†ç›–ï¼ˆå¯é€‰ï¼‰
      - note: ä»»åŠ¡å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰

    è¿”å›:
    {
        "message": "ä»»åŠ¡å·²é‡æ–°æäº¤",
        "new_task_id": "...",
        "original_task_id": "..."
    }
    """
    try:
        import json

        # è·å–åŸä»»åŠ¡ä¿¡æ¯
        original_task = task_manager.get_task(task_id)

        if not original_task:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        # è·å–åŸä»»åŠ¡é…ç½®
        config_dict = task_manager.get_task_config(task_id)

        if not config_dict:
            raise HTTPException(status_code=400, detail="æ— æ³•è·å–ä»»åŠ¡é…ç½®")

        # å¦‚æœè¯·æ±‚ä¸­åŒ…å«é…ç½®è¦†ç›–ï¼Œåˆå¹¶é…ç½®
        if request and request.config:
            logger.info(f"åº”ç”¨é…ç½®è¦†ç›–: {request.config}")
            config_dict.update(request.config)

        # è·å–åŸä»»åŠ¡çš„æ–‡ä»¶ä¿¡æ¯
        # ä¼˜å…ˆä»æ•°æ®åº“ä¸­çš„ request_data è·å–
        request_data = original_task.get("request_data", {})

        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ request_dataï¼Œå°è¯•ä» task_config.json æ–‡ä»¶è¯»å–ï¼ˆå…¼å®¹æ—§ä»»åŠ¡ï¼‰
        if not request_data:
            task_config_file = RESULTS_DIR / task_id / "task_config.json"
            if task_config_file.exists():
                try:
                    with open(task_config_file, 'r', encoding='utf-8') as f:
                        task_config = json.load(f)
                        request_data = task_config.get('request_data', {})
                        logger.info(f"ä» task_config.json è¯»å– request_data: {task_config_file}")
                except Exception as e:
                    logger.warning(f"æ— æ³•ä» task_config.json è¯»å– request_data: {e}")

        if not request_data:
            raise HTTPException(status_code=404, detail=f"æ— æ³•è·å–ä»»åŠ¡ {task_id} çš„æ–‡ä»¶ä¿¡æ¯")

        file_id = request_data.get("file_id")
        dataset_id = request_data.get("dataset_id")
        filename = request_data.get("filename", "")

        # ç¡®å®šæ–‡ä»¶è·¯å¾„
        actual_file_path = None

        # æ–¹æ³•1: ä¼˜å…ˆä½¿ç”¨ dataset_id
        if dataset_id:
            dataset = dataset_db.get_dataset(dataset_id)
            if dataset:
                actual_file_path = Path(dataset["file_path"])
                filename = dataset["original_filename"]  # ä½¿ç”¨åŸå§‹æ–‡ä»¶åè€Œä¸æ˜¯å­˜å‚¨æ–‡ä»¶å
                if actual_file_path.exists():
                    logger.info(f"ä» dataset_id è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")

        # æ–¹æ³•2: å¦‚æœæ²¡æœ‰ dataset_idï¼Œå°è¯•ä½¿ç”¨ file_id
        if (not actual_file_path or not actual_file_path.exists()) and file_id:
            # æ£€æŸ¥æ˜¯å¦ä¸º dataset_id
            dataset = dataset_db.get_dataset(file_id)
            if dataset:
                actual_file_path = Path(dataset["file_path"])
                filename = dataset["original_filename"]  # ä½¿ç”¨åŸå§‹æ–‡ä»¶åè€Œä¸æ˜¯å­˜å‚¨æ–‡ä»¶å
                if actual_file_path.exists():
                    logger.info(f"ä» file_id (ä½œä¸º dataset_id) è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")
            else:
                # å°è¯•ä½œä¸ºä¸Šä¼ æ–‡ä»¶è·¯å¾„
                if filename:
                    actual_file_path = UPLOAD_DIR / file_id / filename
                    if actual_file_path.exists():
                        logger.info(f"ä»ä¸Šä¼ ç›®å½•è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")

        # æ–¹æ³•3: ä» file_path å­—æ®µè·å–ï¼ˆå¯èƒ½æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ï¼‰
        if not actual_file_path or not actual_file_path.exists():
            file_path_str = request_data.get("file_path")
            if file_path_str:
                # å°è¯•ä½œä¸ºç»å¯¹è·¯å¾„
                actual_file_path = Path(file_path_str)
                if not actual_file_path.exists():
                    # å°è¯•ä½œä¸ºç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
                    actual_file_path = BASE_DIR / file_path_str
                    if actual_file_path.exists():
                        logger.info(f"ä» file_path (ç›¸å¯¹è·¯å¾„) è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")
                else:
                    logger.info(f"ä» file_path (ç»å¯¹è·¯å¾„) è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")

        if not actual_file_path or not actual_file_path.exists():
            error_msg = f"æ‰¾ä¸åˆ°åŸä»»åŠ¡çš„æ•°æ®æ–‡ä»¶ã€‚dataset_id={dataset_id}, file_id={file_id}, file_path={request_data.get('file_path')}"
            logger.error(error_msg)
            raise HTTPException(status_code=404, detail=error_msg)

        # åˆ›å»º PredictionConfig å¯¹è±¡
        config = PredictionConfig(**config_dict)

        # åˆ›å»ºæ–°ä»»åŠ¡æ•°æ®
        task_data = {
            "file_path": str(actual_file_path),
            "filename": filename,
            "config": config_dict,
            "total_rows": request_data.get("total_rows"),
            "valid_rows": request_data.get("valid_rows")
        }

        # ä¿å­˜ dataset_id æˆ– file_id
        if dataset_id:
            task_data["dataset_id"] = dataset_id
            task_data["file_id"] = dataset_id
        elif file_id:
            task_data["file_id"] = file_id

        # å¦‚æœè¯·æ±‚ä¸­åŒ…å«å¤‡æ³¨ï¼Œæ·»åŠ åˆ°ä»»åŠ¡æ•°æ®
        if request and request.note:
            task_data["note"] = request.note
            logger.info(f"æ·»åŠ ä»»åŠ¡å¤‡æ³¨: {request.note}")

        # åˆ›å»ºæ–°ä»»åŠ¡
        new_task_id = task_manager.create_task(task_data)
        logger.info(f"Created rerun task: {new_task_id} from original task: {task_id}")

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåœ¨åå°å¯åŠ¨é¢„æµ‹ä»»åŠ¡
        background_tasks.add_task(
            prediction_service.run_prediction,
            task_id=new_task_id,
            file_path=str(actual_file_path),
            config=config
        )

        logger.info(f"Started background prediction for rerun task: {new_task_id}")

        return {
            "message": "ä»»åŠ¡å·²é‡æ–°æäº¤",
            "new_task_id": new_task_id,
            "original_task_id": task_id
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é‡æ–°è¿è¡Œä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é‡æ–°è¿è¡Œä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/{task_id}/incremental-predict")
async def incremental_predict_task(
    task_id: str, 
    background_tasks: BackgroundTasks,
    request: Optional[IncrementalPredictRequest] = None
):
    """
    å¢é‡é¢„æµ‹ä»»åŠ¡ï¼ˆç»§ç»­é¢„æµ‹æœªå®Œæˆçš„æ ·æœ¬ï¼‰

    å‚æ•°:
    - task_id: åŸä»»åŠ¡ID
    - request: å¯é€‰çš„é…ç½®è¦†ç›–

    è¿”å›:
    {
        "message": "å¢é‡é¢„æµ‹ä»»åŠ¡å·²å¯åŠ¨",
        "task_id": "...",
        "original_task_id": "..."
    }
    """
    try:
        from models.schemas import PredictionConfig, TaskStatus
        from config import RESULTS_DIR
        import json

        logger.info(f"Received incremental predict request for task: {task_id}")

        # è·å–åŸä»»åŠ¡ä¿¡æ¯
        original_task = task_manager.get_task(task_id)

        if not original_task:
            logger.error(f"Task not found: {task_id}")
            # å°è¯•åˆ—å‡ºç›®å½•ä¸‹çš„æ–‡ä»¶ä»¥è¾…åŠ©è°ƒè¯•
            try:
                import os
                tasks_dir = task_manager.storage_dir
                files = os.listdir(tasks_dir)
                logger.info(f"Available task files: {files}")
            except:
                pass
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
        
        logger.info(f"Found original task: {original_task.get('task_id')}")

        # è·å–åŸä»»åŠ¡é…ç½®
        config_dict = task_manager.get_task_config(task_id)

        if not config_dict:
            raise HTTPException(status_code=400, detail="æ— æ³•è·å–ä»»åŠ¡é…ç½®")

        # å¦‚æœè¯·æ±‚ä¸­åŒ…å«é…ç½®è¦†ç›–ï¼Œåˆå¹¶é…ç½®
        if request and request.config:
            logger.info(f"åº”ç”¨å¢é‡é¢„æµ‹é…ç½®è¦†ç›–: {request.config}")
            config_dict.update(request.config)

        # æ·»åŠ å¢é‡é¢„æµ‹æ ‡å¿—
        config_dict['continue_from_task_id'] = task_id

        # åˆ›å»ºé…ç½®å¯¹è±¡ï¼ˆæ·»åŠ è¯¦ç»†çš„é”™è¯¯å¤„ç†ï¼‰
        try:
            logger.info(f"å°è¯•åˆ›å»º PredictionConfigï¼Œé…ç½®å­—å…¸keys: {list(config_dict.keys())}")
            config = PredictionConfig(**config_dict)
            logger.info(f"PredictionConfig åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            logger.error(f"åˆ›å»º PredictionConfig å¤±è´¥: {e}", exc_info=True)
            logger.error(f"é…ç½®å­—å…¸å†…å®¹: {config_dict}")
            raise HTTPException(
                status_code=400, 
                detail=f"é…ç½®éªŒè¯å¤±è´¥: {str(e)}"
            )

        # è·å–æ–‡ä»¶è·¯å¾„
        actual_file_path = None
        
        # æ‰“å°å®Œæ•´çš„ä»»åŠ¡ç»“æ„ä»¥ä¾¿è°ƒè¯•
        logger.info(f"å¼€å§‹æŸ¥æ‰¾ä»»åŠ¡ {task_id} çš„æ•°æ®æ–‡ä»¶")
        logger.info(f"original_task é¡¶å±‚ keys: {list(original_task.keys())}")
        
        # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å– dataset_id å’Œ file_id
        request_data = original_task.get("request_data", {})
        
        # å¦‚æœ request_data ä¸ºç©ºï¼Œå°è¯•ä»é¡¶å±‚è·å–
        if not request_data:
            logger.warning("request_data ä¸ºç©ºï¼Œå°è¯•ä»é¡¶å±‚è·å– file_id å’Œ dataset_id")
            dataset_id = original_task.get("dataset_id") or original_task.get("file_id")
            file_id = original_task.get("file_id")
        else:
            dataset_id = request_data.get("dataset_id")
            file_id = request_data.get("file_id")
        
        logger.info(f"request_data keys: {list(request_data.keys())}")
        logger.info(f"dataset_id: {dataset_id}, file_id: {file_id}")

        # æ–¹æ³•1: ä» task_config.json è·å–ï¼ˆé€‚ç”¨äºæ—§ä»»åŠ¡ï¼‰
        task_config_file = RESULTS_DIR / task_id / "task_config.json"
        logger.info(f"æ–¹æ³•1: æ£€æŸ¥ task_config.json: {task_config_file}")
        if task_config_file.exists():
            try:
                with open(task_config_file, 'r', encoding='utf-8') as f:
                    task_config = json.load(f)
                    file_path_str = task_config.get('request_data', {}).get('file_path')
                    logger.info(f"task_config.json ä¸­çš„ file_path: {file_path_str}")
                    if file_path_str:
                        actual_file_path = Path(file_path_str)
                        if actual_file_path.exists():
                            logger.info(f"âœ“ ä» task_config.json è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")
                        else:
                            logger.warning(f"âœ— task_config.json ä¸­çš„è·¯å¾„ä¸å­˜åœ¨: {actual_file_path}")
                            actual_file_path = None
            except Exception as e:
                logger.warning(f"æ— æ³•ä» task_config.json è¯»å–æ–‡ä»¶è·¯å¾„: {e}")
        else:
            logger.warning(f"task_config.json ä¸å­˜åœ¨")

        # æ–¹æ³•2: ä» dataset_id è·å–
        if not actual_file_path or not actual_file_path.exists():
            logger.info(f"æ–¹æ³•2: å°è¯•ä» dataset_id è·å–")
            if dataset_id:
                dataset = dataset_db.get_dataset(dataset_id)
                if dataset:
                    logger.info(f"æ‰¾åˆ°æ•°æ®é›†: {dataset.get('dataset_id')}, file_path: {dataset.get('file_path')}")
                    actual_file_path = Path(dataset['file_path'])
                    if actual_file_path.exists():
                        logger.info(f"âœ“ ä»æ•°æ®é›†æ•°æ®åº“è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")
                    else:
                        logger.warning(f"âœ— æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {actual_file_path}")
                        actual_file_path = None
                else:
                    logger.warning(f"æœªæ‰¾åˆ° dataset_id: {dataset_id}")

        # æ–¹æ³•3: ä» file_id è·å–
        if not actual_file_path or not actual_file_path.exists():
            logger.info(f"æ–¹æ³•3: å°è¯•ä» file_id è·å–")
            if file_id:
                # å°è¯•ä»æ•°æ®é›†æ•°æ®åº“è·å–æ–‡ä»¶è·¯å¾„
                dataset = dataset_db.get_dataset(file_id)
                if dataset:
                    logger.info(f"æ‰¾åˆ°æ•°æ®é›† (é€šè¿‡file_id): {dataset.get('dataset_id')}")
                    actual_file_path = Path(dataset['file_path'])
                    if actual_file_path.exists():
                        logger.info(f"âœ“ ä»æ•°æ®é›†æ•°æ®åº“è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")
                    else:
                        logger.warning(f"âœ— æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {actual_file_path}")
                        actual_file_path = None
                else:
                    # å°è¯•ä»ä¸Šä¼ ç›®å½•è·å–æ–‡ä»¶
                    logger.info(f"å°è¯•ä»ä¸Šä¼ ç›®å½•è·å–: {UPLOAD_DIR / file_id}")
                    file_path = UPLOAD_DIR / file_id
                    if file_path.exists():
                        # æŸ¥æ‰¾å®é™…çš„CSVæ–‡ä»¶
                        csv_files = list(file_path.glob("*.csv"))
                        logger.info(f"ä¸Šä¼ ç›®å½•ä¸­æ‰¾åˆ° {len(csv_files)} ä¸ª CSV æ–‡ä»¶")
                        if csv_files:
                            actual_file_path = csv_files[0]
                            logger.info(f"âœ“ ä»ä¸Šä¼ ç›®å½•è·å–æ–‡ä»¶è·¯å¾„: {actual_file_path}")
                    else:
                        logger.warning(f"ä¸Šä¼ ç›®å½•ä¸å­˜åœ¨: {file_path}")

        # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–æ–‡ä»¶è·¯å¾„
        if not actual_file_path or not actual_file_path.exists():
            logger.error(f"æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œæ— æ³•æ‰¾åˆ°æ•°æ®æ–‡ä»¶")
            logger.error(f"æœ€ç»ˆ actual_file_path: {actual_file_path}")
            raise HTTPException(status_code=404, detail=f"æ— æ³•æ‰¾åˆ°ä»»åŠ¡ {task_id} çš„æ•°æ®æ–‡ä»¶")
        
        logger.info(f"âœ“âœ“âœ“ æˆåŠŸæ‰¾åˆ°æ•°æ®æ–‡ä»¶: {actual_file_path}")


        # é‡ç½®ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        task_manager.update_task_status(
            task_id=task_id,
            status=TaskStatus.RUNNING,
            progress=0.0,
            message="å¼€å§‹å¢é‡é¢„æµ‹..."
        )

        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ BackgroundTasks å¯åŠ¨å¢é‡é¢„æµ‹ï¼ˆä¸ rerun_task ä¿æŒä¸€è‡´ï¼‰
        if config.enable_iteration:
            logger.info(f"Task {task_id}: Detected iterative prediction task, using IterativePredictionService")
            
            def _run_iterative_wrapper(tid, fpath, cfg):
                try:
                    # åˆå§‹åŒ–æœåŠ¡
                    tm = TaskManager()
                    tdb = TaskDatabase()
                    rag = SimpleRAGEngine(
                        max_retrieved_samples=cfg.max_retrieved_samples,
                        similarity_threshold=cfg.similarity_threshold
                    )
                    service = IterativePredictionService(tm, tdb, rag)
                    service.run_task(tid, Path(fpath), cfg)
                except Exception as e:
                    logger.error(f"Iterative wrapper failed: {e}", exc_info=True)
                    tm = TaskManager()
                    tm.update_task(tid, {"status": "failed", "error": str(e)})

            background_tasks.add_task(
                _run_iterative_wrapper,
                tid=task_id,
                fpath=str(actual_file_path),
                cfg=config
            )
        else:
            background_tasks.add_task(
                prediction_service.run_prediction,
                task_id=task_id,
                file_path=str(actual_file_path),
                config=config
            )

        logger.info(f"Started background incremental prediction for task: {task_id}")

        return {
            "message": "å¢é‡é¢„æµ‹ä»»åŠ¡å·²å¯åŠ¨",
            "task_id": task_id,
            "original_task_id": task_id
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¢é‡é¢„æµ‹ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¢é‡é¢„æµ‹ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/{task_id}/cancel")
async def cancel_task(task_id: str):
    """
    å–æ¶ˆä»»åŠ¡

    å‚æ•°:
    - task_id: ä»»åŠ¡ID

    è¿”å›:
    {
        "message": "ä»»åŠ¡å·²å–æ¶ˆ",
        "task_id": "..."
    }
    """
    try:
        task_info = task_manager.get_task(task_id)

        if not task_info:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        # åªèƒ½å–æ¶ˆ pending æˆ– running çŠ¶æ€çš„ä»»åŠ¡
        if task_info.get('status') not in ['pending', 'running']:
            raise HTTPException(
                status_code=400,
                detail=f"æ— æ³•å–æ¶ˆçŠ¶æ€ä¸º {task_info.get('status')} çš„ä»»åŠ¡"
            )

        success = task_manager.cancel_task(task_id)

        if not success:
            raise HTTPException(status_code=500, detail="å–æ¶ˆä»»åŠ¡å¤±è´¥")

        return {
            "message": "ä»»åŠ¡å·²å–æ¶ˆ",
            "task_id": task_id
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/batch-cancel")
async def batch_cancel_tasks(task_ids: list[str]):
    """
    æ‰¹é‡å–æ¶ˆä»»åŠ¡

    å‚æ•°:
    - task_ids: ä»»åŠ¡IDåˆ—è¡¨

    è¿”å›:
    {
        "message": "æ‰¹é‡å–æ¶ˆå®Œæˆ",
        "total": æ€»ä»»åŠ¡æ•°,
        "success": æˆåŠŸæ•°é‡,
        "failed": å¤±è´¥æ•°é‡,
        "results": [
            {"task_id": "...", "success": true/false, "message": "..."}
        ]
    }
    """
    try:
        results = []
        success_count = 0
        failed_count = 0

        for task_id in task_ids:
            try:
                task_info = task_manager.get_task(task_id)

                if not task_info:
                    results.append({
                        "task_id": task_id,
                        "success": False,
                        "message": "ä»»åŠ¡ä¸å­˜åœ¨"
                    })
                    failed_count += 1
                    continue

                # åªæœ‰è¿è¡Œä¸­æˆ–ç­‰å¾…ä¸­çš„ä»»åŠ¡å¯ä»¥å–æ¶ˆ
                if task_info.get("status") not in ["running", "pending"]:
                    results.append({
                        "task_id": task_id,
                        "success": False,
                        "message": f"ä»»åŠ¡çŠ¶æ€ä¸º {task_info.get('status')}ï¼Œæ— æ³•å–æ¶ˆ"
                    })
                    failed_count += 1
                    continue

                success = task_manager.cancel_task(task_id)

                if success:
                    results.append({
                        "task_id": task_id,
                        "success": True,
                        "message": "ä»»åŠ¡å·²å–æ¶ˆ"
                    })
                    success_count += 1
                else:
                    results.append({
                        "task_id": task_id,
                        "success": False,
                        "message": "å–æ¶ˆä»»åŠ¡å¤±è´¥"
                    })
                    failed_count += 1

            except Exception as e:
                logger.error(f"å–æ¶ˆä»»åŠ¡ {task_id} å¤±è´¥: {e}", exc_info=True)
                results.append({
                    "task_id": task_id,
                    "success": False,
                    "message": str(e)
                })
                failed_count += 1

        return {
            "message": "æ‰¹é‡å–æ¶ˆå®Œæˆ",
            "total": len(task_ids),
            "success": success_count,
            "failed": failed_count,
            "results": results
        }

    except Exception as e:
        logger.error(f"æ‰¹é‡å–æ¶ˆä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")


class UpdateNoteRequest(BaseModel):
    """æ›´æ–°ä»»åŠ¡å¤‡æ³¨è¯·æ±‚"""
    note: str


@router.patch("/{task_id}/note")
async def update_task_note(task_id: str, request: UpdateNoteRequest):
    """
    æ›´æ–°ä»»åŠ¡å¤‡æ³¨

    å‚æ•°:
    - task_id: ä»»åŠ¡ID
    - note: æ–°çš„å¤‡æ³¨å†…å®¹

    è¿”å›:
    {
        "message": "å¤‡æ³¨å·²æ›´æ–°",
        "task_id": "...",
        "note": "..."
    }
    """
    try:
        # è·å–ä»»åŠ¡ä¿¡æ¯
        task_info = task_manager.get_task(task_id)

        if not task_info:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        # æ›´æ–°å¤‡æ³¨
        task_manager.update_task(task_id, {"note": request.note})

        return {
            "message": "å¤‡æ³¨å·²æ›´æ–°",
            "task_id": task_id,
            "note": request.note
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°ä»»åŠ¡å¤‡æ³¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ›´æ–°ä»»åŠ¡å¤‡æ³¨å¤±è´¥: {str(e)}")
