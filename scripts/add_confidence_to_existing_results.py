"""
ä¸ºç°æœ‰çš„é¢„æµ‹ç»“æœæ·»åŠ  confidence å­—æ®µ

åŠŸèƒ½ï¼š
1. ä» process_details.json ä¸­è¯»å–æ¯ä¸ªæ ·æœ¬çš„ llm_response
2. ä½¿ç”¨ LLMResponseParser.extract_confidence() æå– confidence å€¼
3. å°† confidence æ·»åŠ åˆ° process_details.json çš„æ¯ä¸ªæ ·æœ¬ä¸­
4. å°† confidence æ·»åŠ åˆ° predictions.csv ä¸­
5. ä¸ä¿®æ”¹ metrics.jsonï¼ˆmetrics æ˜¯é’ˆå¯¹æ•´ä½“æ•°æ®é›†çš„ï¼Œä¸éœ€è¦ confidenceï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/add_confidence_to_existing_results.py <task_id>
    python scripts/add_confidence_to_existing_results.py --all  # å¤„ç†æ‰€æœ‰ä»»åŠ¡
"""

import sys
import json
from pathlib import Path
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from backend.services.simple_rag_engine import LLMResponseParser


def add_confidence_to_task(task_dir: Path, dry_run: bool = False) -> dict:
    """ä¸ºå•ä¸ªä»»åŠ¡æ·»åŠ  confidence å­—æ®µ
    
    Args:
        task_dir: ä»»åŠ¡ç›®å½•è·¯å¾„
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…å†™å…¥æ–‡ä»¶ï¼‰
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    task_id = task_dir.name
    print(f"\n{'='*60}")
    print(f"å¤„ç†ä»»åŠ¡: {task_id}")
    print(f"{'='*60}")
    
    stats = {
        'task_id': task_id,
        'total_samples': 0,
        'samples_with_confidence': 0,
        'samples_without_confidence': 0,
        'updated_process_details': False,
        'updated_predictions_csv': False,
    }
    
    # 1. è¯»å– process_details.json
    process_details_file = task_dir / "process_details.json"
    if not process_details_file.exists():
        print(f"âŒ process_details.json ä¸å­˜åœ¨")
        return stats
    
    with open(process_details_file, 'r', encoding='utf-8') as f:
        process_details = json.load(f)
    
    stats['total_samples'] = len(process_details)
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
    
    # 2. ä¸ºæ¯ä¸ªæ ·æœ¬æå– confidence
    parser = LLMResponseParser()
    updated_count = 0
    
    for detail in process_details:
        llm_response = detail.get('llm_response', '')
        
        # å¦‚æœå·²ç»æœ‰ confidence å­—æ®µï¼Œè·³è¿‡
        if 'confidence' in detail and detail['confidence'] is not None:
            stats['samples_with_confidence'] += 1
            continue
        
        # æå– confidence
        confidence = parser.extract_confidence(llm_response)
        detail['confidence'] = confidence
        
        if confidence:
            stats['samples_with_confidence'] += 1
        else:
            stats['samples_without_confidence'] += 1
        
        updated_count += 1
    
    print(f"âœ… å·²æå– confidence: {stats['samples_with_confidence']} ä¸ªæ ·æœ¬æœ‰ confidence")
    print(f"âš ï¸  æ—  confidence: {stats['samples_without_confidence']} ä¸ªæ ·æœ¬")
    
    # 3. ä¿å­˜æ›´æ–°åçš„ process_details.json
    if not dry_run and updated_count > 0:
        # åˆ›å»ºå¤‡ä»½
        backup_file = task_dir / "process_details.json.backup_before_confidence"
        if not backup_file.exists():
            import shutil
            shutil.copy2(process_details_file, backup_file)
            print(f"ğŸ’¾ å·²åˆ›å»ºå¤‡ä»½: {backup_file.name}")
        
        with open(process_details_file, 'w', encoding='utf-8') as f:
            json.dump(process_details, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ å·²æ›´æ–° process_details.json")
        stats['updated_process_details'] = True
    
    # 4. æ›´æ–° predictions.csvï¼ˆæ·»åŠ  confidence åˆ—ï¼‰
    predictions_file = task_dir / "predictions.csv"
    if predictions_file.exists():
        df = pd.read_csv(predictions_file)
        
        # åˆ›å»º confidence åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if 'confidence' not in df.columns:
            # æ ¹æ® sample_index åŒ¹é… confidence
            confidence_map = {detail['sample_index']: detail.get('confidence') for detail in process_details}
            df['confidence'] = df['sample_index'].map(confidence_map)
            
            if not dry_run:
                df.to_csv(predictions_file, index=False, encoding='utf-8')
                print(f"ğŸ’¾ å·²æ›´æ–° predictions.csvï¼ˆæ·»åŠ  confidence åˆ—ï¼‰")
                stats['updated_predictions_csv'] = True
        else:
            print(f"â„¹ï¸  predictions.csv å·²åŒ…å« confidence åˆ—")
    
    return stats


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸ºç°æœ‰é¢„æµ‹ç»“æœæ·»åŠ  confidence å­—æ®µ')
    parser.add_argument('task_id', nargs='?', help='ä»»åŠ¡IDï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œä½¿ç”¨ --all å¤„ç†æ‰€æœ‰ä»»åŠ¡ï¼‰')
    parser.add_argument('--all', action='store_true', help='å¤„ç†æ‰€æœ‰ä»»åŠ¡')
    parser.add_argument('--dry-run', action='store_true', help='è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…å†™å…¥æ–‡ä»¶ï¼‰')
    
    args = parser.parse_args()
    
    results_dir = project_root / "storage" / "results"
    
    if args.all:
        # å¤„ç†æ‰€æœ‰ä»»åŠ¡
        task_dirs = [d for d in results_dir.iterdir() if d.is_dir()]
        print(f"æ‰¾åˆ° {len(task_dirs)} ä¸ªä»»åŠ¡")
        
        all_stats = []
        for task_dir in task_dirs:
            stats = add_confidence_to_task(task_dir, dry_run=args.dry_run)
            all_stats.append(stats)
        
        # æ‰“å°æ€»ç»“
        print(f"\n{'='*60}")
        print("æ€»ç»“")
        print(f"{'='*60}")
        total_tasks = len(all_stats)
        total_samples = sum(s['total_samples'] for s in all_stats)
        total_with_confidence = sum(s['samples_with_confidence'] for s in all_stats)
        total_without_confidence = sum(s['samples_without_confidence'] for s in all_stats)
        
        print(f"å¤„ç†ä»»åŠ¡æ•°: {total_tasks}")
        print(f"æ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"æœ‰ confidence: {total_with_confidence}")
        print(f"æ—  confidence: {total_without_confidence}")
        
    elif args.task_id:
        # å¤„ç†å•ä¸ªä»»åŠ¡
        task_dir = results_dir / args.task_id
        if not task_dir.exists():
            print(f"âŒ ä»»åŠ¡ç›®å½•ä¸å­˜åœ¨: {task_dir}")
            sys.exit(1)
        
        add_confidence_to_task(task_dir, dry_run=args.dry_run)
    else:
        parser.print_help()
        sys.exit(1)


if __name__ == "__main__":
    main()

